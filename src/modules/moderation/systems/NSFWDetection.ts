import { Message, AttachmentBuilder, EmbedBuilder } from 'discord.js';
import axios from 'axios';
import logger from '../../../utils/logger';

/**
 * Syst√®me de d√©tection NSFW pour les images/vid√©os
 * Utilise une API externe (ex: Sightengine, AWS Rekognition, etc.)
 */
export class NSFWDetectionSystem {
  private cache = new Map<string, { isNSFW: boolean; confidence: number; timestamp: number }>();
  private readonly cacheTimeout = 3600000; // 1 heure

  /**
   * Analyse une image pour d√©tecter du contenu NSFW
   * NOTE: Vous devez configurer une API externe (Sightengine recommand√©)
   */
  private async analyzeImage(url: string): Promise<{ isNSFW: boolean; confidence: number; categories?: string[] } | null> {
    // V√©rifier le cache
    const cached = this.cache.get(url);
    if (cached && Date.now() - cached.timestamp < this.cacheTimeout) {
      return { isNSFW: cached.isNSFW, confidence: cached.confidence };
    }

    const apiKey = process.env.SIGHTENGINE_API_KEY;
    const apiSecret = process.env.SIGHTENGINE_API_SECRET;

    if (!apiKey || !apiSecret) {
      logger.warn('[NSFW Detection] API keys not configured');
      return null;
    }

    try {
      const response = await axios.get('https://api.sightengine.com/1.0/check.json', {
        params: {
          url,
          models: 'nudity-2.0,offensive',
          api_user: apiKey,
          api_secret: apiSecret
        },
        timeout: 10000
      });

      const data = response.data;

      // Analyser les r√©sultats
      const nudityScore = data.nudity?.sexual_activity || 0;
      const offensiveScore = data.offensive?.prob || 0;

      const maxScore = Math.max(nudityScore, offensiveScore);
      const isNSFW = maxScore > 0.6; // Seuil : 60%

      const categories: string[] = [];
      if (nudityScore > 0.6) categories.push('Nudity');
      if (offensiveScore > 0.6) categories.push('Offensive');

      // Mettre en cache
      this.cache.set(url, {
        isNSFW,
        confidence: maxScore,
        timestamp: Date.now()
      });

      return { isNSFW, confidence: maxScore, categories };
    } catch (error) {
      logger.error('[NSFW Detection] API error:', error);
      return null;
    }
  }

  /**
   * V√©rifie un message pour du contenu NSFW
   */
  async checkMessage(message: Message): Promise<{ isNSFW: boolean; attachments: { url: string; confidence: number; categories?: string[] }[] }> {
    if (message.attachments.size === 0) {
      return { isNSFW: false, attachments: [] };
    }

    const results: { url: string; confidence: number; categories?: string[] }[] = [];

    for (const [, attachment] of message.attachments) {
      // V√©rifier uniquement images et vid√©os
      if (!attachment.contentType?.startsWith('image/') && !attachment.contentType?.startsWith('video/')) {
        continue;
      }

      const analysis = await this.analyzeImage(attachment.url);
      if (analysis && analysis.isNSFW) {
        results.push({
          url: attachment.url,
          confidence: analysis.confidence,
          categories: analysis.categories
        });
      }
    }

    return {
      isNSFW: results.length > 0,
      attachments: results
    };
  }

  /**
   * Ex√©cute une action suite √† une d√©tection NSFW
   */
  async executeAction(message: Message, detection: { attachments: { url: string; confidence: number; categories?: string[] }[] }): Promise<void> {
    try {
      // Supprimer le message
      await message.delete();

      const maxConfidence = Math.max(...detection.attachments.map(a => a.confidence));
      const allCategories = [...new Set(detection.attachments.flatMap(a => a.categories || []))];

      // D√©terminer l'action
      if (maxConfidence > 0.9) {
        // Confiance tr√®s √©lev√©e : ban
        await message.member?.ban({ reason: '[Auto-Mod] Contenu NSFW explicite d√©tect√©', deleteMessageSeconds: 86400 });

        await message.channel.send({
          embeds: [new EmbedBuilder()
            .setColor(0xff0000)
            .setTitle('üî® Contenu NSFW d√©tect√©')
            .setDescription(
              `${message.author.tag} a √©t√© **banni** pour partage de contenu NSFW explicite.\n\n` +
              `**Cat√©gories d√©tect√©es:** ${allCategories.join(', ')}\n` +
              `**Confiance:** ${(maxConfidence * 100).toFixed(1)}%`
            )]
        }).then(msg => setTimeout(() => msg.delete().catch(() => {}), 10000));
      } else if (maxConfidence > 0.7) {
        // Confiance √©lev√©e : mute
        await message.member?.timeout(60 * 60 * 1000, '[Auto-Mod] Contenu NSFW d√©tect√©');

        await message.channel.send({
          content: `üîá ${message.author} a √©t√© **mute 1 heure** pour contenu inappropri√©.`,
          allowedMentions: { users: [message.author.id] }
        }).then(msg => setTimeout(() => msg.delete().catch(() => {}), 5000));
      } else {
        // Confiance moyenne : avertissement
        await message.channel.send({
          content: `‚ö†Ô∏è ${message.author}, votre message a √©t√© supprim√© pour contenu potentiellement inappropri√©.`,
          allowedMentions: { users: [message.author.id] }
        }).then(msg => setTimeout(() => msg.delete().catch(() => {}), 5000));
      }

      logger.info(`[NSFW Detection] Action taken for ${message.author.tag} (confidence: ${maxConfidence})`);
    } catch (error) {
      logger.error('[NSFW Detection] Execute action error:', error);
    }
  }

  /**
   * Nettoie le cache expir√©
   */
  clearCache(): void {
    const now = Date.now();
    for (const [url, data] of this.cache.entries()) {
      if (now - data.timestamp > this.cacheTimeout) {
        this.cache.delete(url);
      }
    }
  }
}

export default new NSFWDetectionSystem();
